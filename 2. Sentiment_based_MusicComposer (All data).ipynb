{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Labelled Data\n",
    "\n",
    "This code is used to extract file names of each emotion (happy,sad,suspenseful)\n",
    "\n",
    "The music files are stored in seperate directories for each emotion and the code below reads those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir = '*/labelled data/happy'\n",
    "arr = os.listdir(dir)\n",
    "print(len(arr))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "happy\n",
    "---------\n",
    "\n",
    "[2161, 2572, 2374, 1873, 2201, 2629, 2417, 1876, 2416, 2576, 2562, 2248, 1812, 1813, 2507, 1756, 2075, 1790, 1829, 1752, 1817, 2502, 2516, 1751, 2080, 2334, 1749, 1763, 2083, 2487, 1819, 2509, 2247, 2119, 1835, 1759, 2480, 2292, 2537, 1728, 1933, 2195, 2618, 2156, 1932, 2234, 1739, 2620, 2379, 2147, 1923, 2596, 2186, 2178, 2568]\n",
    "\n",
    "\n",
    "sad\n",
    "-----------\n",
    "[2161, 2572, 2374, 1873, 2201, 2629, 2417, 1876, 2416, 2576, 2562, 2248, 1812, 1813, 2507, 1756, 2075, 1790, 1829, 1752, 1817, 2502, 2516, 1751, 2080, 2334, 1749, 1763, 2083, 2487, 1819, 2509, 2247, 2119, 1835, 1759, 2480, 2292, 2537, 1728, 1933, 2195, 2618, 2156, 1932, 2234, 1739, 2620, 2379, 2147, 1923, 2596, 2186, 2178, 2568]\n",
    "\n",
    "\n",
    "suspense\n",
    "-------------\n",
    "\n",
    "[2203, 2202, 2214, 1735, 2228, 1734, 2573, 2239, 1730, 2166, 2628, 2238, 2159, 2207, 2506, 2473, 2114, 1757, 2104, 2307, 1791, 2477, 2112, 1760, 2678, 1775, 1777, 2478, 1766, 2131, 2285, 2244, 2127, 2222, 2140, 2632, 1919, 2237, 2619, 2180, 2382, 2432, 2591, 2208, 2218, 2227, 2582, 2151, 2622, 2232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set absolute file paths variables\n",
    "datapath = '*/SentimentNet/data/'\n",
    "trainpath = '*/SentimentNet/' \n",
    "experimentspath = '*/SentimentNet/experiments'\n",
    "testfile = '/test_X.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Processing happy ------\n",
      "happy song 0 has 397 windows\n",
      "0 steps of happy song 0 has been done\n",
      "50 steps of happy song 0 has been done\n",
      "100 steps of happy song 0 has been done\n",
      "150 steps of happy song 0 has been done\n",
      "200 steps of happy song 0 has been done\n",
      "250 steps of happy song 0 has been done\n",
      "300 steps of happy song 0 has been done\n",
      "350 steps of happy song 0 has been done\n",
      "happy song 1 has 201 windows\n",
      "0 steps of happy song 1 has been done\n",
      "50 steps of happy song 1 has been done\n",
      "100 steps of happy song 1 has been done\n",
      "150 steps of happy song 1 has been done\n",
      "happy song 2 has 216 windows\n",
      "0 steps of happy song 2 has been done\n",
      "50 steps of happy song 2 has been done\n",
      "100 steps of happy song 2 has been done\n",
      "150 steps of happy song 2 has been done\n",
      "happy song 3 has 367 windows\n",
      "0 steps of happy song 3 has been done\n",
      "50 steps of happy song 3 has been done\n",
      "100 steps of happy song 3 has been done\n",
      "150 steps of happy song 3 has been done\n",
      "200 steps of happy song 3 has been done\n",
      "250 steps of happy song 3 has been done\n",
      "300 steps of happy song 3 has been done\n",
      "happy song 4 has 134 windows\n",
      "0 steps of happy song 4 has been done\n",
      "50 steps of happy song 4 has been done\n",
      "100 steps of happy song 4 has been done\n",
      "happy song 5 has 518 windows\n",
      "0 steps of happy song 5 has been done\n",
      "50 steps of happy song 5 has been done\n",
      "100 steps of happy song 5 has been done\n",
      "150 steps of happy song 5 has been done\n",
      "200 steps of happy song 5 has been done\n",
      "250 steps of happy song 5 has been done\n",
      "300 steps of happy song 5 has been done\n",
      "350 steps of happy song 5 has been done\n",
      "400 steps of happy song 5 has been done\n",
      "450 steps of happy song 5 has been done\n",
      "happy song 6 has 227 windows\n",
      "0 steps of happy song 6 has been done\n",
      "50 steps of happy song 6 has been done\n",
      "100 steps of happy song 6 has been done\n",
      "150 steps of happy song 6 has been done\n",
      "happy song 7 has 357 windows\n",
      "0 steps of happy song 7 has been done\n",
      "50 steps of happy song 7 has been done\n",
      "100 steps of happy song 7 has been done\n",
      "150 steps of happy song 7 has been done\n",
      "200 steps of happy song 7 has been done\n",
      "250 steps of happy song 7 has been done\n",
      "300 steps of happy song 7 has been done\n",
      "happy song 8 has 139 windows\n",
      "0 steps of happy song 8 has been done\n",
      "50 steps of happy song 8 has been done\n",
      "100 steps of happy song 8 has been done\n",
      "happy song 9 has 280 windows\n",
      "0 steps of happy song 9 has been done\n",
      "50 steps of happy song 9 has been done\n",
      "100 steps of happy song 9 has been done\n",
      "150 steps of happy song 9 has been done\n",
      "200 steps of happy song 9 has been done\n",
      "------ Processing sad ------\n",
      "sad song 0 has 795 windows\n",
      "0 steps of sad song 0 has been done\n",
      "50 steps of sad song 0 has been done\n",
      "100 steps of sad song 0 has been done\n",
      "150 steps of sad song 0 has been done\n",
      "200 steps of sad song 0 has been done\n",
      "250 steps of sad song 0 has been done\n",
      "300 steps of sad song 0 has been done\n",
      "350 steps of sad song 0 has been done\n",
      "400 steps of sad song 0 has been done\n",
      "450 steps of sad song 0 has been done\n",
      "500 steps of sad song 0 has been done\n",
      "550 steps of sad song 0 has been done\n",
      "600 steps of sad song 0 has been done\n",
      "650 steps of sad song 0 has been done\n",
      "700 steps of sad song 0 has been done\n",
      "750 steps of sad song 0 has been done\n",
      "sad song 1 has 402 windows\n",
      "0 steps of sad song 1 has been done\n",
      "50 steps of sad song 1 has been done\n",
      "100 steps of sad song 1 has been done\n",
      "150 steps of sad song 1 has been done\n",
      "200 steps of sad song 1 has been done\n",
      "250 steps of sad song 1 has been done\n",
      "300 steps of sad song 1 has been done\n",
      "350 steps of sad song 1 has been done\n",
      "sad song 2 has 433 windows\n",
      "0 steps of sad song 2 has been done\n",
      "50 steps of sad song 2 has been done\n",
      "100 steps of sad song 2 has been done\n",
      "150 steps of sad song 2 has been done\n",
      "200 steps of sad song 2 has been done\n",
      "250 steps of sad song 2 has been done\n",
      "300 steps of sad song 2 has been done\n",
      "350 steps of sad song 2 has been done\n",
      "400 steps of sad song 2 has been done\n",
      "sad song 3 has 734 windows\n",
      "0 steps of sad song 3 has been done\n",
      "50 steps of sad song 3 has been done\n",
      "100 steps of sad song 3 has been done\n",
      "150 steps of sad song 3 has been done\n",
      "200 steps of sad song 3 has been done\n",
      "250 steps of sad song 3 has been done\n",
      "300 steps of sad song 3 has been done\n",
      "350 steps of sad song 3 has been done\n",
      "400 steps of sad song 3 has been done\n",
      "450 steps of sad song 3 has been done\n",
      "500 steps of sad song 3 has been done\n",
      "550 steps of sad song 3 has been done\n",
      "600 steps of sad song 3 has been done\n",
      "650 steps of sad song 3 has been done\n",
      "700 steps of sad song 3 has been done\n",
      "sad song 4 has 268 windows\n",
      "0 steps of sad song 4 has been done\n",
      "50 steps of sad song 4 has been done\n",
      "100 steps of sad song 4 has been done\n",
      "150 steps of sad song 4 has been done\n",
      "200 steps of sad song 4 has been done\n",
      "sad song 5 has 1037 windows\n",
      "0 steps of sad song 5 has been done\n",
      "50 steps of sad song 5 has been done\n",
      "100 steps of sad song 5 has been done\n",
      "150 steps of sad song 5 has been done\n",
      "200 steps of sad song 5 has been done\n",
      "250 steps of sad song 5 has been done\n",
      "300 steps of sad song 5 has been done\n",
      "350 steps of sad song 5 has been done\n",
      "400 steps of sad song 5 has been done\n",
      "450 steps of sad song 5 has been done\n",
      "500 steps of sad song 5 has been done\n",
      "550 steps of sad song 5 has been done\n",
      "600 steps of sad song 5 has been done\n",
      "650 steps of sad song 5 has been done\n",
      "700 steps of sad song 5 has been done\n",
      "750 steps of sad song 5 has been done\n",
      "800 steps of sad song 5 has been done\n",
      "850 steps of sad song 5 has been done\n",
      "900 steps of sad song 5 has been done\n",
      "950 steps of sad song 5 has been done\n",
      "1000 steps of sad song 5 has been done\n",
      "sad song 6 has 455 windows\n",
      "0 steps of sad song 6 has been done\n",
      "50 steps of sad song 6 has been done\n",
      "100 steps of sad song 6 has been done\n",
      "150 steps of sad song 6 has been done\n",
      "200 steps of sad song 6 has been done\n",
      "250 steps of sad song 6 has been done\n",
      "300 steps of sad song 6 has been done\n",
      "350 steps of sad song 6 has been done\n",
      "400 steps of sad song 6 has been done\n",
      "sad song 7 has 714 windows\n",
      "0 steps of sad song 7 has been done\n",
      "50 steps of sad song 7 has been done\n",
      "100 steps of sad song 7 has been done\n",
      "150 steps of sad song 7 has been done\n",
      "200 steps of sad song 7 has been done\n",
      "250 steps of sad song 7 has been done\n",
      "300 steps of sad song 7 has been done\n",
      "350 steps of sad song 7 has been done\n",
      "400 steps of sad song 7 has been done\n",
      "450 steps of sad song 7 has been done\n",
      "500 steps of sad song 7 has been done\n",
      "550 steps of sad song 7 has been done\n",
      "600 steps of sad song 7 has been done\n",
      "650 steps of sad song 7 has been done\n",
      "sad song 8 has 278 windows\n",
      "0 steps of sad song 8 has been done\n",
      "50 steps of sad song 8 has been done\n",
      "100 steps of sad song 8 has been done\n",
      "150 steps of sad song 8 has been done\n",
      "200 steps of sad song 8 has been done\n",
      "sad song 9 has 560 windows\n",
      "0 steps of sad song 9 has been done\n",
      "50 steps of sad song 9 has been done\n",
      "100 steps of sad song 9 has been done\n",
      "150 steps of sad song 9 has been done\n",
      "200 steps of sad song 9 has been done\n",
      "250 steps of sad song 9 has been done\n",
      "300 steps of sad song 9 has been done\n",
      "350 steps of sad song 9 has been done\n",
      "400 steps of sad song 9 has been done\n",
      "450 steps of sad song 9 has been done\n",
      "500 steps of sad song 9 has been done\n",
      "------ Processing suspenseful ------\n",
      "suspenseful song 0 has 625 windows\n",
      "0 steps of suspenseful song 0 has been done\n",
      "50 steps of suspenseful song 0 has been done\n",
      "100 steps of suspenseful song 0 has been done\n",
      "150 steps of suspenseful song 0 has been done\n",
      "200 steps of suspenseful song 0 has been done\n",
      "250 steps of suspenseful song 0 has been done\n",
      "300 steps of suspenseful song 0 has been done\n",
      "350 steps of suspenseful song 0 has been done\n",
      "400 steps of suspenseful song 0 has been done\n",
      "450 steps of suspenseful song 0 has been done\n",
      "500 steps of suspenseful song 0 has been done\n",
      "550 steps of suspenseful song 0 has been done\n",
      "suspenseful song 1 has 725 windows\n",
      "0 steps of suspenseful song 1 has been done\n",
      "50 steps of suspenseful song 1 has been done\n",
      "100 steps of suspenseful song 1 has been done\n",
      "150 steps of suspenseful song 1 has been done\n",
      "200 steps of suspenseful song 1 has been done\n",
      "250 steps of suspenseful song 1 has been done\n",
      "300 steps of suspenseful song 1 has been done\n",
      "350 steps of suspenseful song 1 has been done\n",
      "400 steps of suspenseful song 1 has been done\n",
      "450 steps of suspenseful song 1 has been done\n",
      "500 steps of suspenseful song 1 has been done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 steps of suspenseful song 1 has been done\n",
      "600 steps of suspenseful song 1 has been done\n",
      "650 steps of suspenseful song 1 has been done\n",
      "suspenseful song 2 has 430 windows\n",
      "0 steps of suspenseful song 2 has been done\n",
      "50 steps of suspenseful song 2 has been done\n",
      "100 steps of suspenseful song 2 has been done\n",
      "150 steps of suspenseful song 2 has been done\n",
      "200 steps of suspenseful song 2 has been done\n",
      "250 steps of suspenseful song 2 has been done\n",
      "300 steps of suspenseful song 2 has been done\n",
      "350 steps of suspenseful song 2 has been done\n",
      "suspenseful song 3 has 2864 windows\n",
      "0 steps of suspenseful song 3 has been done\n",
      "50 steps of suspenseful song 3 has been done\n",
      "100 steps of suspenseful song 3 has been done\n",
      "150 steps of suspenseful song 3 has been done\n",
      "200 steps of suspenseful song 3 has been done\n",
      "250 steps of suspenseful song 3 has been done\n",
      "300 steps of suspenseful song 3 has been done\n",
      "350 steps of suspenseful song 3 has been done\n",
      "400 steps of suspenseful song 3 has been done\n",
      "450 steps of suspenseful song 3 has been done\n",
      "500 steps of suspenseful song 3 has been done\n",
      "550 steps of suspenseful song 3 has been done\n",
      "600 steps of suspenseful song 3 has been done\n",
      "650 steps of suspenseful song 3 has been done\n",
      "700 steps of suspenseful song 3 has been done\n",
      "750 steps of suspenseful song 3 has been done\n",
      "800 steps of suspenseful song 3 has been done\n",
      "850 steps of suspenseful song 3 has been done\n",
      "900 steps of suspenseful song 3 has been done\n",
      "950 steps of suspenseful song 3 has been done\n",
      "1000 steps of suspenseful song 3 has been done\n",
      "1050 steps of suspenseful song 3 has been done\n",
      "1100 steps of suspenseful song 3 has been done\n",
      "1150 steps of suspenseful song 3 has been done\n",
      "1200 steps of suspenseful song 3 has been done\n",
      "1250 steps of suspenseful song 3 has been done\n",
      "1300 steps of suspenseful song 3 has been done\n",
      "1350 steps of suspenseful song 3 has been done\n",
      "1400 steps of suspenseful song 3 has been done\n",
      "1450 steps of suspenseful song 3 has been done\n",
      "1500 steps of suspenseful song 3 has been done\n",
      "1550 steps of suspenseful song 3 has been done\n",
      "1600 steps of suspenseful song 3 has been done\n",
      "1650 steps of suspenseful song 3 has been done\n",
      "1700 steps of suspenseful song 3 has been done\n",
      "1750 steps of suspenseful song 3 has been done\n",
      "1800 steps of suspenseful song 3 has been done\n",
      "1850 steps of suspenseful song 3 has been done\n",
      "1900 steps of suspenseful song 3 has been done\n",
      "1950 steps of suspenseful song 3 has been done\n",
      "2000 steps of suspenseful song 3 has been done\n",
      "2050 steps of suspenseful song 3 has been done\n",
      "2100 steps of suspenseful song 3 has been done\n",
      "2150 steps of suspenseful song 3 has been done\n",
      "2200 steps of suspenseful song 3 has been done\n",
      "2250 steps of suspenseful song 3 has been done\n",
      "2300 steps of suspenseful song 3 has been done\n",
      "2350 steps of suspenseful song 3 has been done\n",
      "2400 steps of suspenseful song 3 has been done\n",
      "2450 steps of suspenseful song 3 has been done\n",
      "2500 steps of suspenseful song 3 has been done\n",
      "2550 steps of suspenseful song 3 has been done\n",
      "2600 steps of suspenseful song 3 has been done\n",
      "2650 steps of suspenseful song 3 has been done\n",
      "2700 steps of suspenseful song 3 has been done\n",
      "2750 steps of suspenseful song 3 has been done\n",
      "2800 steps of suspenseful song 3 has been done\n",
      "suspenseful song 4 has 392 windows\n",
      "0 steps of suspenseful song 4 has been done\n",
      "50 steps of suspenseful song 4 has been done\n",
      "100 steps of suspenseful song 4 has been done\n",
      "150 steps of suspenseful song 4 has been done\n",
      "200 steps of suspenseful song 4 has been done\n",
      "250 steps of suspenseful song 4 has been done\n",
      "300 steps of suspenseful song 4 has been done\n",
      "350 steps of suspenseful song 4 has been done\n",
      "suspenseful song 5 has 1304 windows\n",
      "0 steps of suspenseful song 5 has been done\n",
      "50 steps of suspenseful song 5 has been done\n",
      "100 steps of suspenseful song 5 has been done\n",
      "150 steps of suspenseful song 5 has been done\n",
      "200 steps of suspenseful song 5 has been done\n",
      "250 steps of suspenseful song 5 has been done\n",
      "300 steps of suspenseful song 5 has been done\n",
      "350 steps of suspenseful song 5 has been done\n",
      "400 steps of suspenseful song 5 has been done\n",
      "450 steps of suspenseful song 5 has been done\n",
      "500 steps of suspenseful song 5 has been done\n",
      "550 steps of suspenseful song 5 has been done\n",
      "600 steps of suspenseful song 5 has been done\n",
      "650 steps of suspenseful song 5 has been done\n",
      "700 steps of suspenseful song 5 has been done\n",
      "750 steps of suspenseful song 5 has been done\n",
      "800 steps of suspenseful song 5 has been done\n",
      "850 steps of suspenseful song 5 has been done\n",
      "900 steps of suspenseful song 5 has been done\n",
      "950 steps of suspenseful song 5 has been done\n",
      "1000 steps of suspenseful song 5 has been done\n",
      "1050 steps of suspenseful song 5 has been done\n",
      "1100 steps of suspenseful song 5 has been done\n",
      "1150 steps of suspenseful song 5 has been done\n",
      "1200 steps of suspenseful song 5 has been done\n",
      "1250 steps of suspenseful song 5 has been done\n",
      "suspenseful song 6 has 1362 windows\n",
      "0 steps of suspenseful song 6 has been done\n",
      "50 steps of suspenseful song 6 has been done\n",
      "100 steps of suspenseful song 6 has been done\n",
      "150 steps of suspenseful song 6 has been done\n",
      "200 steps of suspenseful song 6 has been done\n",
      "250 steps of suspenseful song 6 has been done\n",
      "300 steps of suspenseful song 6 has been done\n",
      "350 steps of suspenseful song 6 has been done\n",
      "400 steps of suspenseful song 6 has been done\n",
      "450 steps of suspenseful song 6 has been done\n",
      "500 steps of suspenseful song 6 has been done\n",
      "550 steps of suspenseful song 6 has been done\n",
      "600 steps of suspenseful song 6 has been done\n",
      "650 steps of suspenseful song 6 has been done\n",
      "700 steps of suspenseful song 6 has been done\n",
      "750 steps of suspenseful song 6 has been done\n",
      "800 steps of suspenseful song 6 has been done\n",
      "850 steps of suspenseful song 6 has been done\n",
      "900 steps of suspenseful song 6 has been done\n",
      "950 steps of suspenseful song 6 has been done\n",
      "1000 steps of suspenseful song 6 has been done\n",
      "1050 steps of suspenseful song 6 has been done\n",
      "1100 steps of suspenseful song 6 has been done\n",
      "1150 steps of suspenseful song 6 has been done\n",
      "1200 steps of suspenseful song 6 has been done\n",
      "1250 steps of suspenseful song 6 has been done\n",
      "1300 steps of suspenseful song 6 has been done\n",
      "suspenseful song 7 has 480 windows\n",
      "0 steps of suspenseful song 7 has been done\n",
      "50 steps of suspenseful song 7 has been done\n",
      "100 steps of suspenseful song 7 has been done\n",
      "150 steps of suspenseful song 7 has been done\n",
      "200 steps of suspenseful song 7 has been done\n",
      "250 steps of suspenseful song 7 has been done\n",
      "300 steps of suspenseful song 7 has been done\n",
      "350 steps of suspenseful song 7 has been done\n",
      "400 steps of suspenseful song 7 has been done\n",
      "suspenseful song 8 has 1476 windows\n",
      "0 steps of suspenseful song 8 has been done\n",
      "50 steps of suspenseful song 8 has been done\n",
      "100 steps of suspenseful song 8 has been done\n",
      "150 steps of suspenseful song 8 has been done\n",
      "200 steps of suspenseful song 8 has been done\n",
      "250 steps of suspenseful song 8 has been done\n",
      "300 steps of suspenseful song 8 has been done\n",
      "350 steps of suspenseful song 8 has been done\n",
      "400 steps of suspenseful song 8 has been done\n",
      "450 steps of suspenseful song 8 has been done\n",
      "500 steps of suspenseful song 8 has been done\n",
      "550 steps of suspenseful song 8 has been done\n",
      "600 steps of suspenseful song 8 has been done\n",
      "650 steps of suspenseful song 8 has been done\n",
      "700 steps of suspenseful song 8 has been done\n",
      "750 steps of suspenseful song 8 has been done\n",
      "800 steps of suspenseful song 8 has been done\n",
      "850 steps of suspenseful song 8 has been done\n",
      "900 steps of suspenseful song 8 has been done\n",
      "950 steps of suspenseful song 8 has been done\n",
      "1000 steps of suspenseful song 8 has been done\n",
      "1050 steps of suspenseful song 8 has been done\n",
      "1100 steps of suspenseful song 8 has been done\n",
      "1150 steps of suspenseful song 8 has been done\n",
      "1200 steps of suspenseful song 8 has been done\n",
      "1250 steps of suspenseful song 8 has been done\n",
      "1300 steps of suspenseful song 8 has been done\n",
      "1350 steps of suspenseful song 8 has been done\n",
      "1400 steps of suspenseful song 8 has been done\n",
      "suspenseful song 9 has 2561 windows\n",
      "0 steps of suspenseful song 9 has been done\n",
      "50 steps of suspenseful song 9 has been done\n",
      "100 steps of suspenseful song 9 has been done\n",
      "150 steps of suspenseful song 9 has been done\n",
      "200 steps of suspenseful song 9 has been done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 steps of suspenseful song 9 has been done\n",
      "300 steps of suspenseful song 9 has been done\n",
      "350 steps of suspenseful song 9 has been done\n",
      "400 steps of suspenseful song 9 has been done\n",
      "450 steps of suspenseful song 9 has been done\n",
      "500 steps of suspenseful song 9 has been done\n",
      "550 steps of suspenseful song 9 has been done\n",
      "600 steps of suspenseful song 9 has been done\n",
      "650 steps of suspenseful song 9 has been done\n",
      "700 steps of suspenseful song 9 has been done\n",
      "750 steps of suspenseful song 9 has been done\n",
      "800 steps of suspenseful song 9 has been done\n",
      "850 steps of suspenseful song 9 has been done\n",
      "900 steps of suspenseful song 9 has been done\n",
      "950 steps of suspenseful song 9 has been done\n",
      "1000 steps of suspenseful song 9 has been done\n",
      "1050 steps of suspenseful song 9 has been done\n",
      "1100 steps of suspenseful song 9 has been done\n",
      "1150 steps of suspenseful song 9 has been done\n",
      "1200 steps of suspenseful song 9 has been done\n",
      "1250 steps of suspenseful song 9 has been done\n",
      "1300 steps of suspenseful song 9 has been done\n",
      "1350 steps of suspenseful song 9 has been done\n",
      "1400 steps of suspenseful song 9 has been done\n",
      "1450 steps of suspenseful song 9 has been done\n",
      "1500 steps of suspenseful song 9 has been done\n",
      "1550 steps of suspenseful song 9 has been done\n",
      "1600 steps of suspenseful song 9 has been done\n",
      "1650 steps of suspenseful song 9 has been done\n",
      "1700 steps of suspenseful song 9 has been done\n",
      "1750 steps of suspenseful song 9 has been done\n",
      "1800 steps of suspenseful song 9 has been done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #For matrix processing of pianorolls and spectrograms\n",
    "import librosa.output\n",
    "import librosa  #To read audio files\n",
    "from intervaltree import Interval,IntervalTree # The labels are stored in intervaltree data structure for texturenet \n",
    "from scipy import fft \n",
    "import pickle\n",
    "import h5py   #Data format type\n",
    "import sys\n",
    "\n",
    "class hyperparams(object):\n",
    "    def __init__(self):\n",
    "        self.sr = 44100 # Sampling rate.\n",
    "        self.n_fft = 2048 # fft points (samples)\n",
    "        self.stride = 256 # 256 samples hop between windows    \n",
    "        self.wps = 44100 // 256 # ~86 windows/second\n",
    "        \n",
    "        self.sentiment = { \n",
    "                            'happy': [2161, 2572, 2374, 1873, 2201, 2629, 2417, 1876, 2416, 2576, 2562, 2248, 1812, 1813, 2507, 1756, 2075, 1790, 1829, 1752, 1817, 2502, 2516, 1751, 2080, 2334, 1749, 1763, 2083, 2487, 1819, 2509, 2247, 2119, 1835, 1759, 2480, 2292, 2537, 1728, 1933, 2195, 2618, 2156, 1932, 2234, 1739, 2620, 2379, 2147, 1923, 2596, 2186, 2178, 2568],\n",
    "                    \n",
    "                            'sad': [2161, 2572, 2374, 1873, 2201, 2629, 2417, 1876, 2416, 2576, 2562, 2248, 1812, 1813, 2507, 1756, 2075, 1790, 1829, 1752, 1817, 2502, 2516, 1751, 2080, 2334, 1749, 1763, 2083, 2487, 1819, 2509, 2247, 2119, 1835, 1759, 2480, 2292, 2537, 1728, 1933, 2195, 2618, 2156, 1932, 2234, 1739, 2620, 2379, 2147, 1923, 2596, 2186, 2178, 2568],\n",
    "            \n",
    "                            'suspenseful': [2203, 2202, 2214, 1735, 2228, 1734, 2573, 2239, 1730, 2166, 2628, 2238, 2159, 2207, 2506, 2473, 2114, 1757, 2104, 2307, 1791, 2477, 2112, 1760, 2678, 1775, 1777, 2478, 1766, 2131, 2285, 2244, 2127, 2222, 2140, 2632, 1919, 2237, 2619, 2180, 2382, 2432, 2591, 2208, 2218, 2227, 2582, 2151, 2622, 2232]\n",
    "                            }\n",
    "    \n",
    "    #setting windows per sec for each emotion \n",
    "        self.hop_sentiment = {'happy': self.wps, 'sad': int(self.wps * 0.5), 'suspenseful': int(self.wps*0.25)} \n",
    "                      \n",
    "        \n",
    "hp = hyperparams()\n",
    "\n",
    "\n",
    "def get_data(): \n",
    "    '''\n",
    "    Extract the desired solo data from the dataset.\n",
    "    Default: Process emotions of labelled songs\n",
    "    \n",
    "    '''\n",
    "    #Read musicNet data files into dataset \n",
    "    dataset = np.load(open(datapath+'musicnet.npz','rb'), allow_pickle=True, encoding = 'latin1')\n",
    "    \n",
    "    #Preprocess musicNet data files and write values into .hdf5 file below, \n",
    "    train_data = h5py.File(trainpath+'train_sentimentMusic.hdf5', 'w') \n",
    "\n",
    "    #Process each sentiment and store score and audio features\n",
    "    for sent in hp.sentiment:\n",
    "        print ('------ Processing ' + sent + ' ------')\n",
    "        score = []\n",
    "        audio = []\n",
    "        for song in hp.sentiment[sent]: \n",
    "            a,b = dataset[str(song)] \n",
    "            score.append(a) # zero array\n",
    "            audio.append(b) #csv attributes\n",
    "\n",
    "        spec_list, score_list, sentiment_list = process_data(score,audio,sent) \n",
    "        \n",
    "        #For each sentiment, create sepcification list, pianoroll and sentiment label and store in intervaltree\n",
    "        train_data.create_dataset(sent + \"_spec\", data=spec_list)\n",
    "        train_data.create_dataset(sent + \"_pianoroll\", data=score_list)\n",
    "        train_data.create_dataset(sent + \"_onoff\", data=sentiment_list)  \n",
    "\n",
    "def process_data(X, Y, sent):\n",
    "    '''\n",
    "    Data Pre-processing\n",
    "        \n",
    "    Score: \n",
    "        Generate pianoroll from interval tree data structure\n",
    "    \n",
    "    Audio: \n",
    "        Convert waveform into power spectrogram\n",
    "    '''\n",
    "    #Function to read audio spectrogram representation using librosa fourier transform \n",
    "    def process_spectrum(X, step, hop):\n",
    "        audio = X[i][(step * hop * hp.stride): (step * hop * hp.stride) + ((hp.wps*5 - 1)* hp.stride)] \n",
    "        spec = librosa.stft(audio, n_fft= hp.n_fft, hop_length = hp.stride)\n",
    "        #taking log of spectrogram\n",
    "        magnitude = np.log1p(np.abs(spec)**2)\n",
    "        return magnitude\n",
    "\n",
    "    def process_score(Y, step, hop):\n",
    "        score = np.zeros((hp.wps*5, 128))  \n",
    "        onset = np.zeros(score.shape)    \n",
    "        offset = np.zeros(score.shape) \n",
    "\n",
    "        for window in range(score.shape[0]):\n",
    "            \n",
    "            #For score, set all notes to 1 if they are played at this window timestep \n",
    "            labels = Y[i][(step * hop + window) * hp.stride] \n",
    "            for label in labels: \n",
    "                score[window,label.data[1]] = 1 \n",
    "        \n",
    "            #For onset/offset, set onset to 1 and offset to -1 \n",
    "            if window != 0:\n",
    "                onset[window][np.setdiff1d(score[window].nonzero(), score[window-1].nonzero())] = 1\n",
    "                offset[window][np.setdiff1d(score[window-1].nonzero(), score[window].nonzero())] = -1                    \n",
    "            else:\n",
    "                onset[window][score[window].nonzero()] = 1\n",
    "        \n",
    "        onset += offset \n",
    "        return score, onset\n",
    "    \n",
    "    spec_list=[]\n",
    "    score_list=[]\n",
    "    sentiment_list=[]\n",
    "    num_songs = len(X)\n",
    "    hop = hp.hop_sentiment[sent]\n",
    "    for i in range(num_songs):\n",
    "        song_length = len(X[i])\n",
    "        num_spec = (song_length) // (hop * hp.stride) \n",
    "        print ('{} song {} has {} windows'.format(sent, i, num_spec))\n",
    "\n",
    "        for step in range(num_spec - 30):\n",
    "            if step % 50 == 0:\n",
    "                print ('{} steps of {} song {} has been done'.format(step,sent,i))        \n",
    "            spec_list.append(process_spectrum(X,step,hop))\n",
    "            score, onoff = process_score(Y,step,hop)\n",
    "            score_list.append(score)\n",
    "            sentiment_list.append(onoff)\n",
    "\n",
    "    return np.array(spec_list), np.array(score_list), np.array(sentiment_list) #return from process_data\n",
    "\n",
    "\n",
    "def main():  \n",
    "    get_data()\n",
    "   \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter type of emotion to generate (happy, sad, suspenseful) : happy\n",
      "====> Epoch: 0 Average loss: 0.1273\n",
      "====> Test set loss: 0.0795\n",
      "====> Epoch: 1 Average loss: 0.0669\n",
      "====> Epoch: 2 Average loss: 0.0480\n",
      "====> Epoch: 3 Average loss: 0.0397\n",
      "====> Epoch: 4 Average loss: 0.0355\n",
      "====> Epoch: 5 Average loss: 0.0331\n",
      "====> Epoch: 6 Average loss: 0.0346\n",
      "====> Epoch: 7 Average loss: 0.0343\n",
      "====> Epoch: 8 Average loss: 0.0281\n",
      "====> Epoch: 9 Average loss: 0.0269\n",
      "====> Epoch: 10 Average loss: 0.0258\n",
      "====> Test set loss: 0.0272\n",
      "====> Epoch: 11 Average loss: 0.0255\n",
      "====> Epoch: 12 Average loss: 0.0254\n",
      "====> Epoch: 13 Average loss: 0.0244\n",
      "====> Epoch: 14 Average loss: 0.0244\n",
      "====> Epoch: 15 Average loss: 0.0273\n",
      "====> Epoch: 16 Average loss: 0.0246\n",
      "====> Epoch: 17 Average loss: 0.0235\n",
      "====> Epoch: 18 Average loss: 0.0234\n",
      "====> Epoch: 19 Average loss: 0.0236\n",
      "====> Epoch: 20 Average loss: 0.0232\n",
      "====> Test set loss: 0.0248\n",
      "====> Epoch: 21 Average loss: 0.0230\n",
      "====> Epoch: 22 Average loss: 0.0208\n",
      "====> Epoch: 23 Average loss: 0.0201\n",
      "====> Epoch: 24 Average loss: 0.0196\n",
      "====> Epoch: 25 Average loss: 0.0192\n",
      "====> Epoch: 26 Average loss: 0.0196\n",
      "====> Epoch: 27 Average loss: 0.0187\n",
      "====> Epoch: 28 Average loss: 0.0185\n",
      "====> Epoch: 29 Average loss: 0.0179\n",
      "====> Epoch: 30 Average loss: 0.0185\n",
      "====> Test set loss: 0.0207\n",
      "====> Epoch: 31 Average loss: 0.0175\n",
      "====> Epoch: 32 Average loss: 0.0170\n",
      "====> Epoch: 33 Average loss: 0.0168\n",
      "====> Epoch: 34 Average loss: 0.0166\n",
      "====> Epoch: 35 Average loss: 0.0164\n",
      "====> Epoch: 36 Average loss: 0.0156\n",
      "====> Epoch: 37 Average loss: 0.0157\n",
      "====> Epoch: 38 Average loss: 0.0150\n",
      "====> Epoch: 39 Average loss: 0.0150\n",
      "====> Epoch: 40 Average loss: 0.0148\n",
      "====> Test set loss: 0.0172\n",
      "====> Epoch: 41 Average loss: 0.0142\n",
      "====> Epoch: 42 Average loss: 0.0140\n",
      "====> Epoch: 43 Average loss: 0.0145\n",
      "====> Epoch: 44 Average loss: 0.0135\n",
      "====> Epoch: 45 Average loss: 0.0133\n",
      "====> Epoch: 46 Average loss: 0.0131\n",
      "====> Epoch: 47 Average loss: 0.0127\n",
      "====> Epoch: 48 Average loss: 0.0130\n",
      "====> Epoch: 49 Average loss: 0.0128\n",
      "====> Epoch: 50 Average loss: 0.0121\n",
      "====> Test set loss: 0.0151\n",
      "====> Epoch: 51 Average loss: 0.0122\n",
      "====> Epoch: 52 Average loss: 0.0120\n",
      "====> Epoch: 53 Average loss: 0.0119\n",
      "====> Epoch: 54 Average loss: 0.0119\n",
      "====> Epoch: 55 Average loss: 0.0115\n",
      "====> Epoch: 56 Average loss: 0.0110\n",
      "====> Epoch: 57 Average loss: 0.0110\n",
      "====> Epoch: 58 Average loss: 0.0111\n",
      "====> Epoch: 59 Average loss: 0.0106\n",
      "====> Epoch: 60 Average loss: 0.0103\n",
      "====> Test set loss: 0.0141\n",
      "====> Epoch: 61 Average loss: 0.0102\n",
      "====> Epoch: 62 Average loss: 0.0104\n",
      "====> Epoch: 63 Average loss: 0.0103\n",
      "====> Epoch: 64 Average loss: 0.0099\n",
      "====> Epoch: 65 Average loss: 0.0097\n",
      "====> Epoch: 66 Average loss: 0.0098\n",
      "====> Epoch: 67 Average loss: 0.0093\n",
      "====> Epoch: 68 Average loss: 0.0092\n",
      "====> Epoch: 69 Average loss: 0.0091\n",
      "====> Epoch: 70 Average loss: 0.0090\n",
      "====> Test set loss: 0.0119\n",
      "====> Epoch: 71 Average loss: 0.0091\n",
      "====> Epoch: 72 Average loss: 0.0086\n",
      "====> Epoch: 73 Average loss: 0.0088\n",
      "====> Epoch: 74 Average loss: 0.0088\n",
      "====> Epoch: 75 Average loss: 0.0084\n",
      "====> Epoch: 76 Average loss: 0.0081\n",
      "====> Epoch: 77 Average loss: 0.0082\n",
      "====> Epoch: 78 Average loss: 0.0081\n",
      "====> Epoch: 79 Average loss: 0.0081\n",
      "====> Epoch: 80 Average loss: 0.0080\n",
      "====> Test set loss: 0.0107\n",
      "====> Epoch: 81 Average loss: 0.0078\n",
      "====> Epoch: 82 Average loss: 0.0077\n",
      "====> Epoch: 83 Average loss: 0.0074\n",
      "====> Epoch: 84 Average loss: 0.0075\n",
      "====> Epoch: 85 Average loss: 0.0073\n",
      "====> Epoch: 86 Average loss: 0.0072\n",
      "====> Epoch: 87 Average loss: 0.0074\n",
      "====> Epoch: 88 Average loss: 0.0071\n",
      "====> Epoch: 89 Average loss: 0.0072\n",
      "====> Epoch: 90 Average loss: 0.0068\n",
      "====> Test set loss: 0.0102\n",
      "====> Epoch: 91 Average loss: 0.0068\n",
      "====> Epoch: 92 Average loss: 0.0067\n",
      "====> Epoch: 93 Average loss: 0.0068\n",
      "====> Epoch: 94 Average loss: 0.0070\n",
      "====> Epoch: 95 Average loss: 0.0064\n",
      "====> Epoch: 96 Average loss: 0.0065\n",
      "====> Epoch: 97 Average loss: 0.0067\n",
      "====> Epoch: 98 Average loss: 0.0063\n",
      "====> Epoch: 99 Average loss: 0.0061\n",
      "====> Epoch: 100 Average loss: 0.0065\n",
      "====> Test set loss: 0.0098\n",
      "====> Epoch: 101 Average loss: 0.0060\n",
      "====> Epoch: 102 Average loss: 0.0064\n",
      "====> Epoch: 103 Average loss: 0.0064\n",
      "====> Epoch: 104 Average loss: 0.0058\n",
      "====> Epoch: 105 Average loss: 0.0056\n",
      "====> Epoch: 106 Average loss: 0.0059\n",
      "====> Epoch: 107 Average loss: 0.0059\n",
      "====> Epoch: 108 Average loss: 0.0062\n",
      "====> Epoch: 109 Average loss: 0.0058\n",
      "====> Epoch: 110 Average loss: 0.0055\n",
      "====> Test set loss: 0.0087\n",
      "====> Epoch: 111 Average loss: 0.0057\n",
      "====> Epoch: 112 Average loss: 0.0056\n",
      "====> Epoch: 113 Average loss: 0.0055\n",
      "====> Epoch: 114 Average loss: 0.0056\n",
      "====> Epoch: 115 Average loss: 0.0054\n",
      "====> Epoch: 116 Average loss: 0.0053\n",
      "====> Epoch: 117 Average loss: 0.0054\n",
      "====> Epoch: 118 Average loss: 0.0052\n",
      "====> Epoch: 119 Average loss: 0.0054\n",
      "====> Epoch: 120 Average loss: 0.0053\n",
      "====> Test set loss: 0.0083\n",
      "====> Epoch: 121 Average loss: 0.0055\n",
      "====> Epoch: 122 Average loss: 0.0050\n",
      "====> Epoch: 123 Average loss: 0.0050\n",
      "====> Epoch: 124 Average loss: 0.0049\n",
      "====> Epoch: 125 Average loss: 0.0054\n",
      "====> Epoch: 126 Average loss: 0.0047\n",
      "====> Epoch: 127 Average loss: 0.0051\n",
      "====> Epoch: 128 Average loss: 0.0050\n",
      "====> Epoch: 129 Average loss: 0.0049\n",
      "====> Epoch: 130 Average loss: 0.0048\n",
      "====> Test set loss: 0.0079\n",
      "====> Epoch: 131 Average loss: 0.0047\n",
      "====> Epoch: 132 Average loss: 0.0047\n",
      "====> Epoch: 133 Average loss: 0.0046\n",
      "====> Epoch: 134 Average loss: 0.0050\n",
      "====> Epoch: 135 Average loss: 0.0049\n",
      "====> Epoch: 136 Average loss: 0.0046\n",
      "====> Epoch: 137 Average loss: 0.0047\n",
      "====> Epoch: 138 Average loss: 0.0046\n",
      "====> Epoch: 139 Average loss: 0.0043\n",
      "====> Epoch: 140 Average loss: 0.0045\n",
      "====> Test set loss: 0.0078\n",
      "====> Epoch: 141 Average loss: 0.0049\n",
      "====> Epoch: 142 Average loss: 0.0046\n",
      "====> Epoch: 143 Average loss: 0.0044\n",
      "====> Epoch: 144 Average loss: 0.0042\n",
      "====> Epoch: 145 Average loss: 0.0041\n",
      "====> Epoch: 146 Average loss: 0.0044\n",
      "====> Epoch: 147 Average loss: 0.0044\n",
      "====> Epoch: 148 Average loss: 0.0043\n",
      "====> Epoch: 149 Average loss: 0.0046\n",
      "====> Epoch: 150 Average loss: 0.0043\n",
      "====> Test set loss: 0.0073\n",
      "====> Epoch: 151 Average loss: 0.0043\n",
      "====> Epoch: 152 Average loss: 0.0041\n",
      "====> Epoch: 153 Average loss: 0.0041\n",
      "====> Epoch: 154 Average loss: 0.0040\n",
      "====> Epoch: 155 Average loss: 0.0046\n",
      "====> Epoch: 156 Average loss: 0.0042\n",
      "====> Epoch: 157 Average loss: 0.0042\n",
      "====> Epoch: 158 Average loss: 0.0040\n",
      "====> Epoch: 159 Average loss: 0.0039\n",
      "====> Epoch: 160 Average loss: 0.0041\n",
      "====> Test set loss: 0.0077\n",
      "====> Epoch: 161 Average loss: 0.0042\n",
      "====> Epoch: 162 Average loss: 0.0041\n",
      "====> Epoch: 163 Average loss: 0.0040\n",
      "====> Epoch: 164 Average loss: 0.0043\n",
      "====> Epoch: 165 Average loss: 0.0041\n",
      "====> Epoch: 166 Average loss: 0.0041\n",
      "====> Epoch: 167 Average loss: 0.0038\n",
      "====> Epoch: 168 Average loss: 0.0038\n",
      "====> Epoch: 169 Average loss: 0.0037\n",
      "====> Epoch: 170 Average loss: 0.0040\n",
      "====> Test set loss: 0.0069\n",
      "====> Epoch: 171 Average loss: 0.0037\n",
      "====> Epoch: 172 Average loss: 0.0039\n",
      "====> Epoch: 173 Average loss: 0.0039\n",
      "====> Epoch: 174 Average loss: 0.0036\n",
      "====> Epoch: 175 Average loss: 0.0036\n",
      "====> Epoch: 176 Average loss: 0.0040\n",
      "====> Epoch: 177 Average loss: 0.0038\n",
      "====> Epoch: 178 Average loss: 0.0038\n",
      "====> Epoch: 179 Average loss: 0.0036\n",
      "====> Epoch: 180 Average loss: 0.0037\n",
      "====> Test set loss: 0.0064\n",
      "====> Epoch: 181 Average loss: 0.0037\n",
      "====> Epoch: 182 Average loss: 0.0037\n",
      "====> Epoch: 183 Average loss: 0.0038\n",
      "====> Epoch: 184 Average loss: 0.0036\n",
      "====> Epoch: 185 Average loss: 0.0034\n",
      "====> Epoch: 186 Average loss: 0.0035\n",
      "====> Epoch: 187 Average loss: 0.0040\n",
      "====> Epoch: 188 Average loss: 0.0040\n",
      "====> Epoch: 189 Average loss: 0.0036\n",
      "====> Epoch: 190 Average loss: 0.0034\n",
      "====> Test set loss: 0.0067\n",
      "====> Epoch: 191 Average loss: 0.0035\n",
      "====> Epoch: 192 Average loss: 0.0034\n",
      "====> Epoch: 193 Average loss: 0.0036\n",
      "====> Epoch: 194 Average loss: 0.0034\n",
      "====> Epoch: 195 Average loss: 0.0035\n",
      "====> Epoch: 196 Average loss: 0.0034\n",
      "====> Epoch: 197 Average loss: 0.0034\n",
      "====> Epoch: 198 Average loss: 0.0035\n",
      "====> Epoch: 199 Average loss: 0.0034\n",
      "====> Epoch: 200 Average loss: 0.0036\n",
      "====> Test set loss: 0.0061\n",
      "====> Epoch: 201 Average loss: 0.0033\n",
      "====> Epoch: 202 Average loss: 0.0036\n",
      "====> Epoch: 203 Average loss: 0.0033\n",
      "====> Epoch: 204 Average loss: 0.0033\n",
      "====> Epoch: 205 Average loss: 0.0032\n",
      "====> Epoch: 206 Average loss: 0.0033\n",
      "====> Epoch: 207 Average loss: 0.0033\n",
      "====> Epoch: 208 Average loss: 0.0037\n",
      "====> Epoch: 209 Average loss: 0.0035\n",
      "====> Epoch: 210 Average loss: 0.0031\n",
      "====> Test set loss: 0.0063\n",
      "====> Epoch: 211 Average loss: 0.0034\n",
      "====> Epoch: 212 Average loss: 0.0032\n",
      "====> Epoch: 213 Average loss: 0.0031\n",
      "====> Epoch: 214 Average loss: 0.0032\n",
      "====> Epoch: 215 Average loss: 0.0031\n",
      "====> Epoch: 216 Average loss: 0.0030\n",
      "====> Epoch: 217 Average loss: 0.0033\n",
      "====> Epoch: 218 Average loss: 0.0036\n",
      "====> Epoch: 219 Average loss: 0.0032\n",
      "====> Epoch: 220 Average loss: 0.0030\n",
      "====> Test set loss: 0.0065\n",
      "====> Epoch: 221 Average loss: 0.0032\n",
      "====> Epoch: 222 Average loss: 0.0032\n",
      "====> Epoch: 223 Average loss: 0.0032\n",
      "====> Epoch: 224 Average loss: 0.0032\n",
      "====> Epoch: 225 Average loss: 0.0029\n",
      "====> Epoch: 226 Average loss: 0.0034\n",
      "====> Epoch: 227 Average loss: 0.0033\n",
      "====> Epoch: 228 Average loss: 0.0030\n",
      "====> Epoch: 229 Average loss: 0.0030\n",
      "====> Epoch: 230 Average loss: 0.0031\n",
      "====> Test set loss: 0.0060\n",
      "====> Epoch: 231 Average loss: 0.0031\n",
      "====> Epoch: 232 Average loss: 0.0030\n",
      "====> Epoch: 233 Average loss: 0.0032\n",
      "====> Epoch: 234 Average loss: 0.0032\n",
      "====> Epoch: 235 Average loss: 0.0030\n",
      "====> Epoch: 236 Average loss: 0.0030\n",
      "====> Epoch: 237 Average loss: 0.0031\n",
      "====> Epoch: 238 Average loss: 0.0032\n",
      "====> Epoch: 239 Average loss: 0.0029\n",
      "====> Epoch: 240 Average loss: 0.0028\n",
      "====> Test set loss: 0.0061\n",
      "====> Epoch: 241 Average loss: 0.0028\n",
      "====> Epoch: 242 Average loss: 0.0032\n",
      "====> Epoch: 243 Average loss: 0.0031\n",
      "====> Epoch: 244 Average loss: 0.0031\n",
      "====> Epoch: 245 Average loss: 0.0029\n",
      "====> Epoch: 246 Average loss: 0.0029\n",
      "====> Epoch: 247 Average loss: 0.0027\n",
      "====> Epoch: 248 Average loss: 0.0030\n",
      "====> Epoch: 249 Average loss: 0.0029\n",
      "====> Epoch: 250 Average loss: 0.0031\n",
      "====> Test set loss: 0.0057\n",
      "====> Epoch: 251 Average loss: 0.0029\n",
      "====> Epoch: 252 Average loss: 0.0029\n",
      "====> Epoch: 253 Average loss: 0.0028\n",
      "====> Epoch: 254 Average loss: 0.0032\n",
      "====> Epoch: 255 Average loss: 0.0029\n",
      "====> Epoch: 256 Average loss: 0.0028\n",
      "====> Epoch: 257 Average loss: 0.0027\n",
      "====> Epoch: 258 Average loss: 0.0027\n",
      "====> Epoch: 259 Average loss: 0.0028\n",
      "====> Epoch: 260 Average loss: 0.0030\n",
      "====> Test set loss: 0.0061\n",
      "====> Epoch: 261 Average loss: 0.0028\n",
      "====> Epoch: 262 Average loss: 0.0031\n",
      "====> Epoch: 263 Average loss: 0.0029\n",
      "====> Epoch: 264 Average loss: 0.0030\n",
      "====> Epoch: 265 Average loss: 0.0026\n",
      "====> Epoch: 266 Average loss: 0.0026\n",
      "====> Epoch: 267 Average loss: 0.0027\n",
      "====> Epoch: 268 Average loss: 0.0027\n",
      "====> Epoch: 269 Average loss: 0.0028\n",
      "====> Epoch: 270 Average loss: 0.0029\n",
      "====> Test set loss: 0.0060\n",
      "====> Epoch: 271 Average loss: 0.0031\n",
      "====> Epoch: 272 Average loss: 0.0028\n",
      "====> Epoch: 273 Average loss: 0.0026\n",
      "====> Epoch: 274 Average loss: 0.0027\n",
      "====> Epoch: 275 Average loss: 0.0027\n",
      "====> Epoch: 276 Average loss: 0.0030\n",
      "====> Epoch: 277 Average loss: 0.0028\n",
      "====> Epoch: 278 Average loss: 0.0026\n",
      "====> Epoch: 279 Average loss: 0.0027\n",
      "====> Epoch: 280 Average loss: 0.0025\n",
      "====> Test set loss: 0.0060\n",
      "====> Epoch: 281 Average loss: 0.0026\n",
      "====> Epoch: 282 Average loss: 0.0028\n",
      "====> Epoch: 283 Average loss: 0.0027\n",
      "====> Epoch: 284 Average loss: 0.0029\n",
      "====> Epoch: 285 Average loss: 0.0028\n",
      "====> Epoch: 286 Average loss: 0.0027\n",
      "====> Epoch: 287 Average loss: 0.0026\n",
      "====> Epoch: 288 Average loss: 0.0024\n",
      "====> Epoch: 289 Average loss: 0.0026\n",
      "====> Epoch: 290 Average loss: 0.0026\n",
      "====> Test set loss: 0.0068\n",
      "====> Epoch: 291 Average loss: 0.0029\n",
      "====> Epoch: 292 Average loss: 0.0025\n",
      "====> Epoch: 293 Average loss: 0.0025\n",
      "====> Epoch: 294 Average loss: 0.0026\n",
      "====> Epoch: 295 Average loss: 0.0026\n",
      "====> Epoch: 296 Average loss: 0.0026\n",
      "====> Epoch: 297 Average loss: 0.0026\n",
      "====> Epoch: 298 Average loss: 0.0027\n",
      "====> Epoch: 299 Average loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as utils\n",
    "import h5py \n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import json\n",
    "from model import SentimentNet\n",
    "#cuda = torch.device(\"cuda\")\n",
    "cuda = torch.device(\"cpu\")\n",
    "\n",
    "class hyperparams(object):\n",
    "    def __init__(self):\n",
    "        #self.sentiment = 'happy'\n",
    "        self.train_epoch = 300 #change as per required\n",
    "        self.test_freq = 10 #test after every 10 iterations of training the model\n",
    "        self.exp_name = 'sentiment_exp_300'\n",
    "        \n",
    "        self.iter_train_loss = []\n",
    "        self.iter_test_loss = []\n",
    "        self.loss_history = [] #save loss values\n",
    "        self.test_loss_history = []\n",
    "        self.best_loss = 1e10 \n",
    "        self.best_epoch = 0\n",
    "\n",
    "def Process_Data(sent, exp_dir):\n",
    "    #process data as per sent(emotion)\n",
    "    dataset = h5py.File(trainpath+'train_sentimentMusic.hdf5','r')  #hyperparameter tuning\n",
    "    score = dataset['{}_pianoroll'.format(sent)][:] #converting music to it's symbolic representation\n",
    "    spec = dataset['{}_spec'.format(sent)][:]\n",
    "    onoff = dataset['{}_onoff'.format(sent)][:]\n",
    "    score = np.concatenate((score, onoff),axis = -1)\n",
    "    score = np.transpose(score,(0,2,1))\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(score, spec, test_size=0.2) #20% test set\n",
    "    test_data_dir = os.path.join(exp_dir,'test_data') \n",
    "    test_data_dir += '_'+sent\n",
    "    \n",
    "    if (not(path.exists(test_data_dir))):\n",
    "        os.makedirs(test_data_dir)\n",
    "        np.save(os.path.join(test_data_dir, \"test_X.npy\"), X_test)\n",
    "        np.save(os.path.join(test_data_dir, \"test_Y.npy\"), Y_test)\n",
    "        \n",
    "    train_dataset = utils.TensorDataset(torch.Tensor(X_train, device=cuda), torch.Tensor(Y_train, device=cuda))\n",
    "    #change batch_size and verify loss\n",
    "    train_loader = utils.DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "    test_dataset = utils.TensorDataset(torch.Tensor(X_test, device=cuda), torch.Tensor(Y_test,device=cuda))\n",
    "    test_loader = utils.DataLoader(test_dataset, batch_size=5, shuffle=True) \n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train(model, epoch, train_loader, optimizer,iter_train_loss):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):        \n",
    "        optimizer.zero_grad()\n",
    "        split = torch.split(data, 128, dim=1)\n",
    "        y_pred = model(split[0].cuda(),split[1].cuda())\n",
    "        loss_function = nn.MSELoss()\n",
    "        loss = loss_function(y_pred, target.cuda())\n",
    "        loss.backward()\n",
    "        iter_train_loss.append(loss.item())\n",
    "        train_loss += loss\n",
    "        optimizer.step()    \n",
    "         \n",
    "        #if batch_idx % 2 == 0:\n",
    "         #   print ('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Loss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx/len(train_loader), loss.item()/len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss/ len(train_loader.dataset)))\n",
    "    return train_loss/ len(train_loader.dataset)\n",
    "\n",
    "def test(model, epoch, test_loader, scheduler, iter_test_loss):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        for idx, (data, target) in enumerate(test_loader):\n",
    "            split = torch.split(data,128,dim = 1)\n",
    "            y_pred = model(split[0].cuda(),split[1].cuda())\n",
    "            loss_function = nn.MSELoss() \n",
    "            loss = loss_function(y_pred,target.cuda())    \n",
    "            iter_test_loss.append(loss.item())\n",
    "            test_loss += loss    \n",
    "        test_loss/= len(test_loader.dataset)\n",
    "        scheduler.step(test_loss)\n",
    "        print ('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "        return test_loss\n",
    "\n",
    "\n",
    "def main():    \n",
    "    hp = hyperparams()\n",
    "\n",
    "    try:\n",
    "        exp_root = os.path.join(os.path.abspath(trainpath),'experiments')\n",
    "        os.makedirs(exp_root)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    exp_dir = os.path.join(exp_root, hp.exp_name)\n",
    "    #check if already exists\n",
    "    if (not(path.exists(exp_dir))):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    model = SentimentNet()\n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    #train_loader, test_loader = Process_Data(hp.sentiment, exp_dir)\n",
    "    \n",
    "    s = input(\"Enter type of emotion to generate (happy, sad, suspenseful) : \")\n",
    "    \n",
    "    if(s not in ['happy','sad','suspenseful']):\n",
    "        print('Enter valid emotion')\n",
    "    else:\n",
    "        train_loader, test_loader = Process_Data(s, exp_dir)\n",
    "    \n",
    "        for epoch in range(hp.train_epoch):\n",
    "            loss = train(model, epoch, train_loader, optimizer,hp.iter_train_loss)\n",
    "            hp.loss_history.append(loss.item())\n",
    "            if epoch % hp.test_freq == 0:\n",
    "                test_loss = test(model, epoch, test_loader, scheduler, hp.iter_test_loss)\n",
    "                hp.test_loss_history.append(test_loss.item())\n",
    "                if test_loss < hp.best_loss:         \n",
    "                    torch.save({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'optimizer' : optimizer.state_dict()}, os.path.join(exp_dir, 'checkpoint-{}.tar'.format(str(epoch + 1 ))))\n",
    "                    hp.best_loss = test_loss.item()    \n",
    "                    hp.best_epoch = epoch + 1\n",
    "                    \n",
    "                    hpath = exp_dir + '/test_data_'+s\n",
    "                    with open(os.path.join(hpath,'hyperparams.json'), 'w') as outfile:\n",
    "                        json.dump(hp.__dict__, outfile)\n",
    "       \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as utils\n",
    "import sys\n",
    "import pickle as pkl\n",
    "\n",
    "#cuda = torch.device(\"cuda\") #if available\n",
    "cuda = torch.device(\"cpu\")\n",
    "\n",
    "def conv1x3(in_channels, out_channels, stride=1, padding=1, bias=True,groups=1):\n",
    "    return nn.Conv1d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        bias=bias,\n",
    "        groups=groups)\n",
    "\n",
    "def upconv1x2(in_channels, out_channels, kernel):\n",
    "    return nn.ConvTranspose1d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=kernel,\n",
    "        stride=2,\n",
    "        padding=1\n",
    "        )\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block_id, pooling = True):\n",
    "        super(DownConv,self).__init__()\n",
    "        self.in_channels = in_channels \n",
    "        self.out_channels = out_channels \n",
    "        self.pooling = pooling            \n",
    "        self.activation = nn.LeakyReLU(0.01)\n",
    "        self.conv1 = conv1x3(self.in_channels, self.out_channels) \n",
    "        self.conv1_BN = nn.InstanceNorm1d(self.out_channels)\n",
    "        self.conv2 = conv1x3(self.out_channels, self.out_channels) \n",
    "        self.conv2_BN = nn.InstanceNorm1d(self.out_channels)  \n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.activation(self.conv1_BN(self.conv1(x)))\n",
    "        x = self.activation(self.conv1_BN(self.conv2(x)))\n",
    "        before_pool = x\n",
    "        if self.pooling:\n",
    "            x = self.pool(x)\n",
    "        return x, before_pool\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, skip_channels, cond_channels, block_id, activation = nn.LeakyReLU(0.01), upconv_kernel=2):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.skip_channels = skip_channels  \n",
    "        self.in_channels = in_channels \n",
    "        self.out_channels = out_channels\n",
    "        self.cond_channels = cond_channels\n",
    "        self.activation = activation\n",
    "        self.upconv = upconv1x2(self.in_channels, self.out_channels,kernel=upconv_kernel)\n",
    "        self.upconv_BN = nn.InstanceNorm1d(self.out_channels) \n",
    "        self.conv1 = conv1x3( self.skip_channels + self.out_channels, self.out_channels)   \n",
    "        self.conv1_BN = nn.InstanceNorm1d(self.out_channels)\n",
    "        self.conv2 = conv1x3(self.out_channels + self.cond_channels, self.out_channels) \n",
    "        self.conv2_BN = nn.InstanceNorm1d(self.out_channels)\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "        bypass = F.pad(bypass, (-c, -c))\n",
    "        if bypass.shape[2] > upsampled.shape[2]:\n",
    "            bypass =  F.pad(bypass, (0, -(bypass.shape[2] - upsampled.shape[2])))  \n",
    "        else:\n",
    "            bypass =  F.pad(bypass, ((0, bypass.shape[2] - upsampled.shape[2]) ))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    " \n",
    "    def forward(self, res, dec, cond):\n",
    "        x = self.activation(self.upconv_BN(self.upconv(dec)))\n",
    "        x = self.crop_and_concat(x, res)\n",
    "        x = self.activation(self.conv1_BN(self.conv1(x)))\n",
    "\n",
    "        if self.cond_channels:\n",
    "            x = self.crop_and_concat(x, cond)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.activation(self.conv2_BN(x))\n",
    "        return x   \n",
    "\n",
    "class Onset_Offset_Encoder(nn.Module):\n",
    "    def __init__(self, depth = 3, start_channels = 128):\n",
    "        super(Onset_Offset_Encoder, self).__init__()\n",
    "        self.start_channels = start_channels\n",
    "        self.depth = depth\n",
    "        self.down_convs = [] \n",
    "        self.construct_layers()    \n",
    "        self.down_convs = nn.ModuleList(self.down_convs)\n",
    "        self.reset_params()\n",
    "    def construct_layers(self):\n",
    "        for i in range(self.depth):\n",
    "            ins = self.start_channels if i == 0 else outs\n",
    "            outs = self.start_channels * (2 ** (i+1))\n",
    "            pooling = True if i < self.depth else False\n",
    "            DC = DownConv(ins, outs, pooling=pooling, block_id = i + 9)\n",
    "            self.down_convs.append(DC)\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            init.xavier_normal_(m.weight)\n",
    "            init.constant_(m.bias, 0)\n",
    "    def reset_params(self):\n",
    "        for i, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "    def forward(self, x):\n",
    "        condition_tensors = []\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x,_ = module(x)\n",
    "            if (i > self.depth - 3):\n",
    "                condition_tensors.append(x)\n",
    "        return condition_tensors\n",
    "\n",
    "class MBRBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_of_band):\n",
    "        super(MBRBlock, self).__init__()\n",
    "        self.in_dim = in_channels\n",
    "        self.num_of_band = num_of_band\n",
    "        self.conv_list1 = []\n",
    "        self.bn_list1 = []\n",
    "        self.conv_list2 = []\n",
    "        self.bn_list2 = []\n",
    "        self.activation = nn.LeakyReLU(0.01)\n",
    "        self.band_dim = self.in_dim // self.num_of_band\n",
    "        for i in range(self.num_of_band):\n",
    "            self.conv_list1.append(nn.Conv1d(in_channels = self.band_dim, out_channels = self.band_dim, kernel_size = 3, padding = 1))\n",
    "        for i in range(self.num_of_band):\n",
    "            self.conv_list2.append(nn.Conv1d(in_channels = self.band_dim, out_channels = self.band_dim, kernel_size = 3, padding = 1))\n",
    "        for i in range(self.num_of_band):\n",
    "            self.bn_list1.append(nn.InstanceNorm1d(self.band_dim))\n",
    "        for i in range(self.num_of_band):  \n",
    "            self.bn_list2.append(nn.InstanceNorm1d(self.band_dim))  \n",
    "        self.conv_list1 = nn.ModuleList(self.conv_list1)\n",
    "        self.conv_list2 = nn.ModuleList(self.conv_list2)        \n",
    "        self.bn_list1 = nn.ModuleList(self.bn_list1)\n",
    "        self.bn_list2 = nn.ModuleList(self.bn_list2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        bands = torch.chunk(x, self.num_of_band, dim = 1)\n",
    "        for i in range(len(bands)):\n",
    "            t = self.activation(self.bn_list1[i](self.conv_list1[i](bands[i])))\n",
    "            t = self.bn_list2[i](self.conv_list2[i](t))\n",
    "            torch.add(bands[i],1,t)\n",
    "        x = torch.add(x,1,torch.cat(bands, dim = 1))\n",
    "        return x \n",
    "     \n",
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, depth = 5,start_channels = 128):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.start_channels = start_channels  \n",
    "        self.construct_layers()\n",
    "        self.reset_params()               \n",
    "        \n",
    "    #@staticmethod  \n",
    "    def construct_layers(self):\n",
    "        self.down_convs = []\n",
    "        self.up_convs = []\n",
    "        for i in range(self.depth):\n",
    "            ins = self.start_channels if i == 0 else outs\n",
    "            outs = self.start_channels * (2 ** (i+1))\n",
    "            pooling = True if i < self.depth-1 else False\n",
    "            DC = DownConv(ins, outs, pooling=pooling, block_id=i)\n",
    "            self.down_convs.append(DC)  \n",
    "        self.up_convs.append(UpConv(4096,2048,2048, 1024, block_id = 5, upconv_kernel=6))\n",
    "        self.up_convs.append(UpConv(2048,1024,1024, 512, block_id = 6, upconv_kernel=4))\n",
    "        self.up_convs.append(UpConv(1024,1024,512,0,block_id= 7, upconv_kernel=3))\n",
    "        self.up_convs.append(UpConv(1024,1024,256,0, block_id = 8))\n",
    "        self.down_convs = nn.ModuleList(self.down_convs)\n",
    "        self.up_convs = nn.ModuleList(self.up_convs)\n",
    "        self.MBRBlock1 = MBRBlock(1024,2) \n",
    "        self.MBRBlock2 = MBRBlock(1024,4)\n",
    "        self.MBRBlock3 = MBRBlock(1024,8)\n",
    "        self.MBRBlock4 = MBRBlock(1024,16)\n",
    "        self.lastconv = nn.ConvTranspose1d(1024,1025,kernel_size=3, stride=1, padding=1)\n",
    "        self.lrelu = nn.LeakyReLU(0.01)\n",
    "        self.onset_offset_encoder = Onset_Offset_Encoder()\n",
    "        \n",
    "    @staticmethod  \n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            init.xavier_normal_(m.weight)\n",
    "            init.constant_(m.bias, 0)\n",
    "        if isinstance(m, nn.ConvTranspose1d):\n",
    "            init.xavier_normal_(m.weight)\n",
    "            init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def reset_params(self):\n",
    "        for i, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "    \n",
    "    def forward(self, x, cond):\n",
    "        encoder_layer_outputs = []\n",
    "        for i, module in enumerate(self.down_convs):\n",
    "            x, before_pool = module(x)\n",
    "            encoder_layer_outputs.append(before_pool)\n",
    "\n",
    "        Onoff_Conditions = self.onset_offset_encoder(cond)   \n",
    "\n",
    "        for i, module in enumerate(self.up_convs):\n",
    "            before_pool = encoder_layer_outputs[-(i+2)]\n",
    "            if i < self.onset_offset_encoder.depth - 1:\n",
    "                x = module(before_pool, x, Onoff_Conditions[i-1])            \n",
    "            else:\n",
    "                x = module(before_pool, x, None)\n",
    "                \n",
    "        x = self.MBRBlock1(x)\n",
    "        x = self.MBRBlock2(x)\n",
    "        x = self.MBRBlock3(x)\n",
    "        x = self.MBRBlock4(x)\n",
    "        x = self.lrelu(self.lastconv(x)) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter type of emotion to generate (happy, sad, suspense) : happy\n",
      "Generating output wav file......\n",
      "Synthesizing audio 1\n",
      "Synthesizing audio 2\n",
      "Synthesizing audio 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as utils\n",
    "import json\n",
    "import os\n",
    "from model import SentimentNet\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "class AudioSynthesizer():\n",
    "    def __init__(self, checkpoint, exp_dir, data_source, inputsentiment):\n",
    "        self.sentiment = inputsentiment\n",
    "        self.exp_dir = exp_dir\n",
    "        self.checkpoint = torch.load(os.path.join(exp_dir,checkpoint))\n",
    "        self.sample_rate = 44100\n",
    "        self.wps = 44100//256\n",
    "        self.data_source = data_source\n",
    "                \n",
    "    def get_test_midi(self):\n",
    "        exppath = os.path.join(self.exp_dir,'test_data')\n",
    "        exppath += '_'+ self.sentiment\n",
    "        \n",
    "        X = np.load(exppath + testfile)\n",
    "        \n",
    "        rand = np.random.randint(len(X),size=)1 ## output file\n",
    "        score = [X[i] for i in rand]\n",
    "        return torch.Tensor(score).cuda()\n",
    "\n",
    "    def process_custom_midi(self, midi_filename):\n",
    "        midi_dir = os.path.join('*/SentimentNet/data','midi')\n",
    "        midi = pretty_midi.PrettyMIDI(os.path.join(midi_dir,'goldsaucer_happy'))\n",
    "        pianoroll = midi.get_piano_roll(fs=self.wps).T\n",
    "        pianoroll[pianoroll.nonzero()] = 1\n",
    "        onoff = np.zeros(pianoroll.shape) \n",
    "        \n",
    "        for i in range(pianoroll.shape[0]):\n",
    "            if i == 0:\n",
    "                onoff[i][pianoroll[i].nonzero()] = 1\n",
    "            else:\n",
    "                onoff[i][np.setdiff1d(pianoroll[i-1].nonzero(), pianoroll[i].nonzero())] = -1\n",
    "                onoff[i][np.setdiff1d(pianoroll[i].nonzero(), pianoroll[i-1].nonzero())] = 1 \n",
    "        \n",
    "        return pianoroll, onoff\n",
    "\n",
    "\n",
    "    def inference(self):\n",
    "        model = SentimentNet()\n",
    "        #model.cpu() #CUDA cout of memory control\n",
    "        model.cuda()\n",
    "        model.load_state_dict(self.checkpoint['state_dict'])\n",
    "\n",
    "        if self.data_source == 'TEST_DATA':\n",
    "            score = self.get_test_midi()\n",
    "            score, onoff = torch.split(score, 128, dim=1)\n",
    "        else:\n",
    "            score, onoff = self.process_custom_midi(self.data_source)\n",
    "                   \n",
    "        print ('Generating output wav file......')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()    \n",
    "            test_results = model(score, onoff)\n",
    "            test_results = test_results.cpu().numpy()\n",
    " \n",
    "        output_dir = self.create_output_dir()\n",
    "\n",
    "        for i in range(len(test_results)):\n",
    "            audio = self.griffinlim(test_results[i], audio_id = i+1)\n",
    "            librosa.output.write_wav(os.path.join(output_dir,'output-{}.wav'.format(i+1)), audio, self.sample_rate)\n",
    "    \n",
    "    def create_output_dir(self):\n",
    "        success = False\n",
    "        dir_id = 1\n",
    "        while not success:\n",
    "            try:\n",
    "                audio_out_dir = os.path.join(self.exp_dir,'audio_output_{}_{}'.format(self.sentiment,dir_id))\n",
    "                #audio_out_dir = os.path.join(self.exp_dir,'audio_output_{}'.format(dir_id))\n",
    "                os.makedirs(audio_out_dir)\n",
    "                success = True\n",
    "            except FileExistsError:\n",
    "                dir_id += 1\n",
    "        return audio_out_dir\n",
    "\n",
    "    def griffinlim(self, spectrogram, audio_id, n_iter = 300, window = 'hann', n_fft = 2048, hop_length = 256, verbose = False):\n",
    "        \n",
    "        print ('Synthesizing audio {}'.format(audio_id))\n",
    "\n",
    "        if hop_length == -1:\n",
    "            hop_length = n_fft // 4\n",
    "            spectrogram[0:5] = 0 #audio representaion of music\n",
    "\n",
    "        spectrogram[150:] = 0\n",
    "        angles = np.exp(2j * np.pi * np.random.rand(*spectrogram.shape))\n",
    "\n",
    "        t = tqdm(range(n_iter), ncols=100, mininterval=2.0, disable=not verbose)\n",
    "        for i in t:\n",
    "            full = np.abs(spectrogram).astype(np.complex) * angles\n",
    "            inverse = librosa.istft(full, hop_length = hop_length, window = window)\n",
    "            rebuilt = librosa.stft(inverse, n_fft = n_fft, hop_length = hop_length, window = window)\n",
    "            angles = np.exp(1j * np.angle(rebuilt))\n",
    "\n",
    "            if verbose:\n",
    "                diff = np.abs(spectrogram) - np.abs(rebuilt)\n",
    "                t.set_postfix(loss=np.linalg.norm(diff, 'fro'))\n",
    "\n",
    "        full = np.abs(spectrogram).astype(np.complex) * angles\n",
    "        inverse = librosa.istft(full, hop_length = hop_length, window = window)\n",
    "\n",
    "        return inverse\n",
    "\n",
    "\n",
    "def main():\n",
    "    exp_dir = '*/SentimentNet/experiments/sentiment_exp_300'\n",
    "    data_source = 'TEST_DATA' # test with testing data or customized data \n",
    "\n",
    "    s = input(\"Enter type of emotion to generate (happy, sad, suspense) : \")\n",
    "    if(s not in ['happy','sad','suspenseful']):\n",
    "        print('Enter valid emotion')\n",
    "    else:\n",
    "        #hp = hyperparams()\n",
    "        #hp.sentiment = s\n",
    "        hpath = exp_dir + '/test_data_'+s\n",
    "        with open(os.path.join(hpath,'hyperparams.json'), 'r') as hpfile:\n",
    "            hp = json.load(hpfile)\n",
    "            \n",
    "        checkpoints = 'checkpoint-{}.tar'.format(hp['best_epoch'])\n",
    "        AudioSynth = AudioSynthesizer(checkpoints, exp_dir, data_source,s) \n",
    "        AudioSynth.inference()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
